{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e23c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_KAGGLE = False\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    INPUT_FOLDER = '/kaggle/input/linking-writing-processes-to-writing-quality'\n",
    "else:\n",
    "    INPUT_FOLDER = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3aea01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-4.1.0.tar.gz (1.7 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/ehabelkady/Desktop/new_env/lib/python3.10/site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/ehabelkady/Desktop/new_env/lib/python3.10/site-packages (from lightgbm) (1.11.1)\n",
      "Building wheels for collected packages: lightgbm\n",
      "  Building wheel for lightgbm (pyproject.toml) ... \u001b[?25l/^C\n",
      "\u001b[?25canceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491fb36e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression, LogisticRegression\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, KFold\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d99cc",
   "metadata": {},
   "source": [
    "**id** - The unique ID of the essay\n",
    "\n",
    "**event_id** - The index of the event, ordered chronologically\n",
    "\n",
    "**down_time** - The time of the down event in milliseconds\n",
    "\n",
    "**up_time** - The time of the up event in milliseconds\n",
    "\n",
    "**action_time** - The duration of the event (the difference between down_time and up_time)\n",
    "\n",
    "**activity** - The category of activity which the event belongs to\n",
    "\n",
    "- **Nonproduction** - The event does not alter the text in any way\n",
    "\n",
    "- **Input** - The event adds text to the essay\n",
    "\n",
    "- **Remove/Cut** - The event removes text from the essay\n",
    "\n",
    "- **Paste** - The event changes the text through a paste input\n",
    "\n",
    "- **Replace** - The event replaces a section of text with another string\n",
    "\n",
    "- **Move From [x1, y1] To [x2, y2]** - The event moves a section of text spanning character index x1, y1 to a new location x2, y2\n",
    "\n",
    "**down_event** - The name of the event when the key/mouse is pressed\n",
    "\n",
    "**up_event** - The name of the event when the key/mouse is released\n",
    "\n",
    "**text_change** - The text that changed as a result of the event (if any)\n",
    "\n",
    "**cursor_position** - The character index of the text cursor after the event\n",
    "\n",
    "**word_count** - The word count of the essay after the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    df_raw_train = pd.read_csv(f'{INPUT_FOLDER}/train_logs.csv')\n",
    "    df_raw_test = pd.read_csv(f'{INPUT_FOLDER}/test_logs.csv')\n",
    "    df_raw = pd.concat((df_raw_train, df_raw_test)).reset_index(False)\n",
    "    df = pd.DataFrame({\n",
    "    'id': df_raw[\"id\"].unique()\n",
    "    })\n",
    "    df['is_test'] = df['id'].isin(df_raw_test['id'].unique())\n",
    "    df_word = df_raw.groupby(\"id\")['word_count'].max()\n",
    "    df = pd.merge(df, df_word, on=\"id\", how=\"left\")\n",
    "    df_raw['current_min'] = df_raw[\"down_time\"]//60000\n",
    "    df_event = df_raw.groupby(\"id\")['event_id'].count()\n",
    "\n",
    "    df = pd.merge(df, df_event, on=\"id\", how=\"left\")\n",
    "    df = df.rename(columns={\"event_id\": \"event_count\"})\n",
    "    df_time = df_raw.groupby(\"id\")['current_min'].max()\n",
    "    df = pd.merge(df, df_time, on=\"id\", how=\"left\")\n",
    "    df = df.rename(columns={\"current_min\": \"writing_time_min\"})\n",
    "    df['events_per_min'] = df[\"event_count\"] / df['writing_time_min']\n",
    "    filter_text_change = df_raw[\"text_change\"]!=\"NoChange\"\n",
    "    df_filtered = df_raw[filter_text_change]\n",
    "    df_text_change = df_filtered.groupby(\"id\")['text_change'].count()\n",
    "\n",
    "    df = pd.merge(df, df_text_change, on=\"id\", how=\"left\")\n",
    "    df = df.rename(columns={\"text_change\": \"text_change_count\"})\n",
    "    df['text_changes_per_min'] = df[\"text_change_count\"] / df['writing_time_min']\n",
    "    sentence_filter = df_raw[(df_raw[\"text_change\"].str.match('\\.')) & (df_raw['activity'] != 'Remove/Cut')]\n",
    "    sentence_filter = df_raw[df_raw[\"up_event\"] == '.']\n",
    "    df_sentence_count = sentence_filter.groupby(\"id\")['text_change'].count()\n",
    "\n",
    "    df = pd.merge(df, df_sentence_count, on=\"id\", how=\"left\")\n",
    "    df = df.rename(columns={\"text_change\": \"sentence_count\"})\n",
    "    for activity in ['Input', 'Remove/Cut', 'Paste', 'Replace', 'Nonproduction']:\n",
    "      df_activity_count = df_raw[df_raw['activity'] == activity].groupby(\"id\")['activity'].count()\n",
    "      column_name = f'{activity}_count'\n",
    "      df_activity_count.name = column_name\n",
    "      df = pd.merge(df, df_activity_count, on=\"id\", how=\"left\")\n",
    "      df[column_name] = df[column_name].fillna(0)\n",
    "    df_raw['IKI'] = df_raw['down_time'] - df_raw.groupby('id')['up_time'].shift(1)\n",
    "    df_raw['IKI'] = df_raw['IKI'].fillna(0)\n",
    "    df_raw['IKI'] = df_raw['IKI'].clip(0)\n",
    "\n",
    "    PAUSE_THRESHOLD = 2000\n",
    "\n",
    "    # Total number of pauses (over 2000 ms) during writing process\n",
    "    pauses_count = df_raw[df_raw['IKI'] > PAUSE_THRESHOLD].groupby('id')['IKI'].count()\n",
    "    pauses_count.name = 'pauses_count'\n",
    "    df = pd.merge(df, pauses_count, on=\"id\", how=\"left\")\n",
    "    pauses_mean_duration = df_raw[df_raw['IKI'] > PAUSE_THRESHOLD].groupby('id')['IKI'].mean().round(0)\n",
    "    pauses_mean_duration.name = 'pause_mean_duration'\n",
    "    df = pd.merge(df, pauses_mean_duration, on=\"id\", how=\"left\")\n",
    "    pauses_time_sum = df_raw[df_raw['IKI'] > PAUSE_THRESHOLD].groupby('id')['IKI'].sum()\n",
    "    pauses_time_sum.name = 'pauses_time_sum'\n",
    "    df = pd.merge(df, pauses_time_sum, on=\"id\", how=\"left\")\n",
    "    writing_time_ms = df_raw.groupby('id')['up_time'].max()\n",
    "    writing_time_ms.name = 'writing_time_ms'\n",
    "    df = pd.merge(df, writing_time_ms, on=\"id\", how=\"left\")\n",
    "    # Average number of pauses per minute\n",
    "    df['pause_per_min'] = (df[\"pauses_count\"] / df['writing_time_min']).round(2)\n",
    "\n",
    "    # Proportion of pauses during the writing process\n",
    "    df['pauses_share'] = (df[\"pauses_time_sum\"] / df['writing_time_ms']).round(2)\n",
    "    df_freq = df_raw.groupby(\"id\").agg({\n",
    "      'down_time': ['min', 'max'],\n",
    "      'activity': lambda x: x.value_counts().index[0]\n",
    "    }).reset_index()\n",
    "    df_freq.columns = ['id', 'start_time', 'end_time', 'most_frequent_activity']\n",
    "    df = pd.merge(df, df_freq, on=\"id\", how='left')\n",
    "    # Calculating Average action time\n",
    "    df['total_writing_time'] = df['end_time'] - df['start_time']\n",
    "    df['Avg_time_between_events'] = df['total_writing_time'] / df['event_count']\n",
    "    # If overtime writing (if the writing time exceeded 30 minutes)\n",
    "    df['overtime_writing'] = df['writing_time_min'] > 30\n",
    "    # Average Action Time - average duration of the actions for each essay.\n",
    "    # Summing the durations of all actions in an essay and then dividing by the total number of actions.\n",
    "    # I leave values in the milliseconds due to it is very short in duration\n",
    "\n",
    "    total_action_time = df_raw.groupby('id')['action_time'].sum()\n",
    "    df = pd.merge(df, total_action_time, on='id', how='left')\n",
    "\n",
    "    df['average_action_time'] = df['action_time'] / df['event_count']\n",
    "    df = df.drop(columns=['action_time'])\n",
    "    df_raw['chars_added'] = df_raw['activity'].apply(lambda x: 1 if x in ['Input', 'Paste'] else 0)\n",
    "    df_raw['chars_removed'] = df_raw['activity'].apply(lambda x: 1 if x == 'Remove/Cut' else 0)\n",
    "\n",
    "    total_chars_added = df_raw.groupby('id')['chars_added'].sum()\n",
    "    total_chars_removed = df_raw.groupby('id')['chars_removed'].sum()\n",
    "\n",
    "    df = pd.merge(df, total_chars_added, on='id', how='left')\n",
    "    df = pd.merge(df, total_chars_removed, on='id', how='left')\n",
    "\n",
    "    df['total_characters'] = df['chars_added'] - df['chars_removed']\n",
    "    df.drop(columns=['chars_added', 'chars_removed'], inplace=True)\n",
    "    df['avg_characters_per_min'] = df['total_characters'] / df['writing_time_min']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f89f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb510b",
   "metadata": {},
   "source": [
    "# Multicorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58189046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(f\"{INPUT_FOLDER}/train_scores.csv\")\n",
    "df = pd.merge(df, df_labels, on='id', how='left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson correlation matrix\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "matrix = numeric_df.corr()\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40857b9a",
   "metadata": {},
   "source": [
    "Multicollinearity is indicated by the fact that the correlation between some pairs of features is stronger than their correlation with the dependent variable (score). For example the matrix shows the maximum correlation between the characteristics total_writing_time and writing_time_min (0.99) and it is greater than the correlation of either argument with the investigated characteristic, so we can draw the conclusion that these 2 characteristics are too strongly related to each other and in the same model both should not appear at the same time.\n",
    "\n",
    "To simplify the task we will choose a treshold of 0.9, considering that to be a very strong correlation.\n",
    "\n",
    "We will start with writing down pairs of features that are highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd31b35",
   "metadata": {},
   "source": [
    "#total_characters - word_count\n",
    "\n",
    "events_per_min - event_count\n",
    "\n",
    "text_change_count - event_count\n",
    "\n",
    "Input_count - event_count\n",
    "\n",
    "#end_time - writing_time_min\n",
    "\n",
    "#writing_time_ms - writing_time_min\n",
    "\n",
    "text_changes_per_min - events_per_min\n",
    "\n",
    "total_characters - text_change_count\n",
    "\n",
    "text_changes_per_min - text_change_count\n",
    "\n",
    "Input_count - text_change_count\n",
    "\n",
    "text_changes_per_min - Input_count\n",
    "\n",
    "text_changes_per_min - avg_characters_per_min\n",
    "\n",
    "#Input_count - word_count\n",
    "\n",
    "Input_count - total_characters\n",
    "\n",
    "#writing_time_ms - end_time\n",
    "\n",
    "#total_characters - avg_characters_per_min\n",
    "\n",
    "#pause_per_min - pause_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683066bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "df_model = copy.deepcopy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f008bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e71d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will drop Input_count, writing_time_min, end_time, avg_characters_per_min, pause_per_min,\n",
    "#events_per_min, total_characters,text_change_count.\n",
    "\n",
    "\n",
    "#Drop one feature from the pair.\n",
    "\n",
    "columns_to_drop = ['Input_count', 'writing_time_min', 'end_time', 'avg_characters_per_min',  'pause_per_min', 'events_per_min', 'total_characters', 'text_change_count']\n",
    "df_model.drop(columns=columns_to_drop , inplace=True)\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.drop(columns='score')\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a34d394",
   "metadata": {},
   "source": [
    "## Preprocessing to be done:\n",
    "\n",
    "- Handle any missing values.\n",
    "- Encode categorical features if present.\n",
    "- Splitting the Data\n",
    "- Dealing with the imbalansed data\n",
    "- Normalize or standardize numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8f14e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_features = df_model.isnull().sum()\n",
    "missing_values_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a2ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['pauses_count'].fillna(df_model['pauses_count'].mean(), inplace=True)\n",
    "df_model['pause_mean_duration'].fillna(df_model['pause_mean_duration'].median(), inplace=True)\n",
    "df_model['pauses_time_sum'].fillna(df_model['pauses_time_sum'].mean(), inplace=True)\n",
    "df_model['sentence_count'].fillna(df_model['sentence_count'].mean(), inplace=True)\n",
    "df_model['pauses_share'].fillna(df_model['pauses_share'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b30b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_features_imputated = df_model.isnull().sum()\n",
    "missing_values_features_imputated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4189a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Encoding 'most_frequent_activity' using one-hot encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "most_frequent_activity_encoded = encoder.fit_transform(df_model[['most_frequent_activity']])\n",
    "\n",
    "# Converting encoded data into a DataFrame\n",
    "columns = encoder.get_feature_names_out(['most_frequent_activity'])\n",
    "df_most_frequent_activity_encoded = pd.DataFrame(most_frequent_activity_encoded, columns=columns)\n",
    "\n",
    "# Converting 'overtime_writing' from boolean to numeric (0 and 1)\n",
    "df_model['overtime_writing'] = df_model['overtime_writing'].astype(int)\n",
    "\n",
    "# Dropping the original 'most_frequent_activity' column and adding the encoded columns\n",
    "df_features_encoded = df_model.drop(['most_frequent_activity'], axis=1)\n",
    "df_features_encoded = pd.concat([df_features_encoded, df_most_frequent_activity_encoded], axis=1)\n",
    "\n",
    "df_features_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea0ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels['class'] = (df_labels['score'] * 2).astype(int)\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c72fd",
   "metadata": {},
   "source": [
    "# Preparations for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1843d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_features_encoded.drop(['id'], axis=1)\n",
    "X = X.fillna(0)\n",
    "y_class = df_labels['class']\n",
    "y_score = df_labels['score']  # Keep for regression\n",
    "\n",
    "X_test = X[X['is_test'] == True].drop(['is_test'], axis=1)\n",
    "X = X[X['is_test'] == False].drop(['is_test'], axis=1)\n",
    "\n",
    "X_train, X_val, y_train_class, y_val_class = train_test_split(X, y_class, random_state=0, test_size=0.20, stratify=y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faa911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa22fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote_tomek = SMOTETomek(random_state=27, smote=SMOTE(k_neighbors=3))\n",
    "X_overunder, y_overunder = smote_tomek.fit_resample(X_train, y_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd46471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_overunder.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b411f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled = y_overunder / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf02f53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Normalising the data\n",
    "# More info: https://towardsdatascience.com/what-and-why-behind-fit-transform-vs-transform-in-scikit-learn-78f915cf96fe\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_train_normalized = pd.DataFrame(X_train_normalized, columns=X_train.columns)\n",
    "X_train_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_normalized = scaler.transform(X_val)\n",
    "X_val_normalized = pd.DataFrame(X_val_normalized, columns=X_val.columns)\n",
    "#X_val_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337259e3",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c0fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_reg = LogisticRegression()\n",
    "l_reg.fit(X_train, y_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = l_reg.predict(X_val)\n",
    "mean_squared_error(y_pred, y_val_class, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80232759",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_lr = l_reg.predict(X_test_normalized)\n",
    "test_pred_lr = test_pred_lr/2.0\n",
    "test_pred_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_lr = pd.DataFrame({\n",
    "    \"id\": df[df['is_test'] == True]['id'],\n",
    "    \"score\": test_pred_lr\n",
    "})\n",
    "df_result_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12dbc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_lr.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716e20a",
   "metadata": {},
   "source": [
    "## LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac68180",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'reg_alpha': 0.007678095440286993,\n",
    "               'reg_lambda': 0.34230534302168353,\n",
    "               'colsample_bytree': 0.627061253588415,\n",
    "               'subsample': 0.854942238828458,\n",
    "               'learning_rate': 0.04,   #0.038697981947473245,\n",
    "               'num_leaves': 22,\n",
    "               'max_depth': 37,\n",
    "               'min_child_samples': 18,\n",
    "               'n_jobs':4\n",
    "              }\n",
    "params = {\n",
    "      \"objective\": \"regression\",\n",
    "      \"metric\": \"rmse\",\n",
    "      'random_state': 42,\n",
    "      \"n_estimators\" : 12001,\n",
    "      \"verbosity\": -1,\n",
    "      **best_params\n",
    "  }\n",
    "model = lgb.LGBMRegressor(**params)\n",
    "early_stopping_callback = lgb.early_stopping(100, first_metric_only=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4267b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_normalized, y_train_resampled, eval_set=[(X_val_normalized, y_val_class)],\n",
    "                  callbacks=[early_stopping_callback],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0826d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model.predict(X_val_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(val_pred, y_val_class, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264be0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_lgb = model.predict(X_test_normalized)\n",
    "test_pred_lgb = test_pred_lgb\n",
    "test_pred_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8936c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_lgb = pd.DataFrame({\n",
    "    \"id\": df[df['is_test'] == True]['id'],\n",
    "    \"score\": test_pred_lgb\n",
    "})\n",
    "df_result_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985fce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_lgb.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1323f9f",
   "metadata": {},
   "source": [
    "## RandomForest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg.fit(X_train, y_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = rf_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af17278",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(val_pred, y_val_class, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404fda60",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = rf_reg.predict(X_test_normalized)\n",
    "test_pred_rf = test_pred_lgb\n",
    "test_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e5e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_rf = pd.DataFrame({\n",
    "    \"id\": df[df['is_test'] == True]['id'],\n",
    "    \"score\": test_pred_rf\n",
    "})\n",
    "df_result_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4209b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_rf.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
